{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import PMMLPipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn2pmml.decoration import ContinuousDomain\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a simple decision tree model for the classification of iris species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd=pd.read_pickle(\"closing_date_dynamic.pickle\")\n",
    "plt.figure(figsize=(15,5))\n",
    "column_names=cd.columns.values+\"_log_return\"\n",
    "log_return_data = pd.DataFrame()\n",
    "for i in range(0,len(column_names)):\n",
    "    log_return_data[column_names[i]]=np.log(cd.iloc[:,i]/cd.iloc[:,i].shift())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snp_log_return_positive</th>\n",
       "      <th>snp_log_return_1</th>\n",
       "      <th>snp_log_return_2</th>\n",
       "      <th>snp_log_return_3</th>\n",
       "      <th>nyse_log_return_1</th>\n",
       "      <th>nyse_log_return_2</th>\n",
       "      <th>nyse_log_return_3</th>\n",
       "      <th>djia_log_return_1</th>\n",
       "      <th>djia_log_return_2</th>\n",
       "      <th>djia_log_return_3</th>\n",
       "      <th>...</th>\n",
       "      <th>hangseng_log_return_2</th>\n",
       "      <th>ftse_log_return_0</th>\n",
       "      <th>ftse_log_return_1</th>\n",
       "      <th>ftse_log_return_2</th>\n",
       "      <th>dax_log_return_0</th>\n",
       "      <th>dax_log_return_1</th>\n",
       "      <th>dax_log_return_2</th>\n",
       "      <th>aord_log_return_0</th>\n",
       "      <th>aord_log_return_1</th>\n",
       "      <th>aord_log_return_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>-0.008206</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.010608</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>-0.016273</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>-0.006408</td>\n",
       "      <td>-0.010007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>-0.008206</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.010608</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026231</td>\n",
       "      <td>-0.022504</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>-0.019033</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>-0.006408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>-0.012392</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001456</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.022504</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>-0.019033</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>-0.008127</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.005962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>-0.012392</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002895</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.022504</td>\n",
       "      <td>-0.021129</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>-0.019033</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>-0.008127</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010389</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>-0.015413</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>-0.012392</td>\n",
       "      <td>-0.011466</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>-0.001376</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.018030</td>\n",
       "      <td>-0.021129</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>-0.009338</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>-0.008127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   snp_log_return_positive  snp_log_return_1  snp_log_return_2  \\\n",
       "0                      1.0          0.006919         -0.008206   \n",
       "1                      0.0          0.003158          0.006919   \n",
       "2                      1.0         -0.010420          0.003158   \n",
       "3                      0.0          0.011572         -0.010420   \n",
       "4                      0.0         -0.010389          0.011572   \n",
       "\n",
       "   snp_log_return_3  nyse_log_return_1  nyse_log_return_2  nyse_log_return_3  \\\n",
       "0          0.001609           0.008066          -0.010608           0.003187   \n",
       "1         -0.008206           0.002471           0.008066          -0.010608   \n",
       "2          0.006919          -0.012392           0.002471           0.008066   \n",
       "3          0.003158           0.011742          -0.012392           0.002471   \n",
       "4         -0.010420          -0.015413           0.011742          -0.012392   \n",
       "\n",
       "   djia_log_return_1  djia_log_return_2  djia_log_return_3        ...          \\\n",
       "0           0.005023          -0.003450           0.004304        ...           \n",
       "1           0.002784           0.005023          -0.003450        ...           \n",
       "2          -0.009465           0.002784           0.005023        ...           \n",
       "3           0.010854          -0.009465           0.002784        ...           \n",
       "4          -0.011466           0.010854          -0.009465        ...           \n",
       "\n",
       "   hangseng_log_return_2  ftse_log_return_0  ftse_log_return_1  \\\n",
       "0              -0.003794           0.012212          -0.006803   \n",
       "1              -0.026231          -0.022504           0.012212   \n",
       "2              -0.001456           0.002067          -0.022504   \n",
       "3              -0.002895           0.001376           0.002067   \n",
       "4               0.001099          -0.001376           0.001376   \n",
       "\n",
       "   ftse_log_return_2  dax_log_return_0  dax_log_return_1  dax_log_return_2  \\\n",
       "0          -0.001355          0.004307          0.003383         -0.016273   \n",
       "1          -0.006803         -0.019033          0.004307          0.003383   \n",
       "2           0.012212          0.016961         -0.019033          0.004307   \n",
       "3          -0.022504         -0.021129          0.016961         -0.019033   \n",
       "4           0.002067         -0.018030         -0.021129          0.016961   \n",
       "\n",
       "   aord_log_return_0  aord_log_return_1  aord_log_return_2  \n",
       "0           0.005962          -0.006408          -0.010007  \n",
       "1           0.000020           0.005962          -0.006408  \n",
       "2          -0.008127           0.000020           0.005962  \n",
       "3           0.001124          -0.008127           0.000020  \n",
       "4          -0.009338           0.001124          -0.008127  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=log_return_data.columns.values\n",
    "correlated_columns=[\"snp\",\"nyse\",\"djia\"]\n",
    "def create_empty_training_test_dataframe():\n",
    "    new_column=column_names[0]+\"_positive\"\n",
    "    new_column_names=[]\n",
    "    for i in range(0,len(column_names)):\n",
    "        if \"snp\" in column_names[i] or \"nyse\" in column_names[i] or \"djia\" in column_names[i]:\n",
    "            for k in range(1,4):\n",
    "                new_column_names.append(column_names[i]+\"_\"+str(k))\n",
    "        else:\n",
    "            for k in range(0,3):\n",
    "                new_column_names.append(column_names[i]+\"_\"+str(k))\n",
    "    new_column_names.insert(0,new_column)\n",
    "    training_test_data = pd.DataFrame(\n",
    "      columns=new_column_names)\n",
    "    return training_test_data.copy()\n",
    "\n",
    "new_column=column_names[0]+\"_positive\"\n",
    "log_return_data[new_column]=0\n",
    "log_return_data.loc[log_return_data.iloc[:,0] >= 0, new_column] = 1\n",
    "training_test_data=create_empty_training_test_dataframe()\n",
    "column_names_training_test=training_test_data.columns.values\n",
    "# print (column_names_training_test)\n",
    "\n",
    "for i in range(8,len(log_return_data)):\n",
    "    temp_dict={}\n",
    "    temp_dict[column_names_training_test[0]] = log_return_data[new_column].iloc[i]\n",
    "    for j in range(0,len(column_names)):\n",
    "        if correlated_columns[0] in column_names[j] or correlated_columns[1] in column_names[j] or\\\n",
    "        correlated_columns[2] in column_names[j]:\n",
    "            for k in range(1,4):\n",
    "                temp_dict[column_names[j]+\"_\"+str(k)] = log_return_data[column_names[j]].iloc[i-k]\n",
    "        else:\n",
    "            for k in range(0,3):\n",
    "                temp_dict[column_names[j]+\"_\"+str(k)] = log_return_data[column_names[j]].iloc[i-k]\n",
    "\n",
    "    \n",
    "    training_test_data=training_test_data.append(temp_dict,ignore_index=True)\n",
    "    \n",
    "training_test_data=training_test_data.dropna()\n",
    "training_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snp_log_return_1</th>\n",
       "      <th>snp_log_return_2</th>\n",
       "      <th>snp_log_return_3</th>\n",
       "      <th>nyse_log_return_1</th>\n",
       "      <th>nyse_log_return_2</th>\n",
       "      <th>nyse_log_return_3</th>\n",
       "      <th>djia_log_return_1</th>\n",
       "      <th>djia_log_return_2</th>\n",
       "      <th>djia_log_return_3</th>\n",
       "      <th>nikkei_log_return_0</th>\n",
       "      <th>...</th>\n",
       "      <th>hangseng_log_return_2</th>\n",
       "      <th>ftse_log_return_0</th>\n",
       "      <th>ftse_log_return_1</th>\n",
       "      <th>ftse_log_return_2</th>\n",
       "      <th>dax_log_return_0</th>\n",
       "      <th>dax_log_return_1</th>\n",
       "      <th>dax_log_return_2</th>\n",
       "      <th>aord_log_return_0</th>\n",
       "      <th>aord_log_return_1</th>\n",
       "      <th>aord_log_return_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "      <td>1151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009881</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011726</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.009021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.064430</td>\n",
       "      <td>-0.064430</td>\n",
       "      <td>-0.064430</td>\n",
       "      <td>-0.073116</td>\n",
       "      <td>-0.073116</td>\n",
       "      <td>-0.073116</td>\n",
       "      <td>-0.057061</td>\n",
       "      <td>-0.057061</td>\n",
       "      <td>-0.057061</td>\n",
       "      <td>-0.111534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058270</td>\n",
       "      <td>-0.104804</td>\n",
       "      <td>-0.104804</td>\n",
       "      <td>-0.104804</td>\n",
       "      <td>-0.064195</td>\n",
       "      <td>-0.064195</td>\n",
       "      <td>-0.064195</td>\n",
       "      <td>-0.042998</td>\n",
       "      <td>-0.042998</td>\n",
       "      <td>-0.042998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003936</td>\n",
       "      <td>-0.003966</td>\n",
       "      <td>-0.003936</td>\n",
       "      <td>-0.004430</td>\n",
       "      <td>-0.004465</td>\n",
       "      <td>-0.004430</td>\n",
       "      <td>-0.003868</td>\n",
       "      <td>-0.003868</td>\n",
       "      <td>-0.003855</td>\n",
       "      <td>-0.006897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005713</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>-0.006947</td>\n",
       "      <td>-0.005552</td>\n",
       "      <td>-0.005552</td>\n",
       "      <td>-0.005620</td>\n",
       "      <td>-0.004583</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>-0.004596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.043229</td>\n",
       "      <td>0.043229</td>\n",
       "      <td>0.043229</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.055223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055187</td>\n",
       "      <td>0.102029</td>\n",
       "      <td>0.102029</td>\n",
       "      <td>0.102029</td>\n",
       "      <td>0.052104</td>\n",
       "      <td>0.052104</td>\n",
       "      <td>0.052104</td>\n",
       "      <td>0.034368</td>\n",
       "      <td>0.034368</td>\n",
       "      <td>0.034368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       snp_log_return_1  snp_log_return_2  snp_log_return_3  \\\n",
       "count       1151.000000       1151.000000       1151.000000   \n",
       "mean           0.000428          0.000412          0.000418   \n",
       "std            0.009881          0.009880          0.009879   \n",
       "min           -0.064430         -0.064430         -0.064430   \n",
       "25%           -0.003936         -0.003966         -0.003936   \n",
       "50%            0.000852          0.000847          0.000852   \n",
       "75%            0.005500          0.005458          0.005458   \n",
       "max            0.043229          0.043229          0.043229   \n",
       "\n",
       "       nyse_log_return_1  nyse_log_return_2  nyse_log_return_3  \\\n",
       "count        1151.000000        1151.000000        1151.000000   \n",
       "mean            0.000323           0.000305           0.000314   \n",
       "std             0.010921           0.010922           0.010920   \n",
       "min            -0.073116          -0.073116          -0.073116   \n",
       "25%            -0.004430          -0.004465          -0.004430   \n",
       "50%             0.000648           0.000645           0.000648   \n",
       "75%             0.005926           0.005911           0.005911   \n",
       "max             0.051173           0.051173           0.051173   \n",
       "\n",
       "       djia_log_return_1  djia_log_return_2  djia_log_return_3  \\\n",
       "count        1151.000000        1151.000000        1151.000000   \n",
       "mean            0.000385           0.000372           0.000380   \n",
       "std             0.009345           0.009340           0.009339   \n",
       "min            -0.057061          -0.057061          -0.057061   \n",
       "25%            -0.003868          -0.003868          -0.003855   \n",
       "50%             0.000562           0.000560           0.000562   \n",
       "75%             0.005099           0.005079           0.005079   \n",
       "max             0.041533           0.041533           0.041533   \n",
       "\n",
       "       nikkei_log_return_0        ...          hangseng_log_return_2  \\\n",
       "count          1151.000000        ...                    1151.000000   \n",
       "mean              0.000298        ...                       0.000073   \n",
       "std               0.013828        ...                       0.011726   \n",
       "min              -0.111534        ...                      -0.058270   \n",
       "25%              -0.006897        ...                      -0.005713   \n",
       "50%               0.000000        ...                       0.000000   \n",
       "75%               0.008605        ...                       0.006420   \n",
       "max               0.055223        ...                       0.055187   \n",
       "\n",
       "       ftse_log_return_0  ftse_log_return_1  ftse_log_return_2  \\\n",
       "count        1151.000000        1151.000000        1151.000000   \n",
       "mean            0.000414           0.000399           0.000398   \n",
       "std             0.014508           0.014507           0.014507   \n",
       "min            -0.104804          -0.104804          -0.104804   \n",
       "25%            -0.006947          -0.006947          -0.006947   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.007067           0.007050           0.007050   \n",
       "max             0.102029           0.102029           0.102029   \n",
       "\n",
       "       dax_log_return_0  dax_log_return_1  dax_log_return_2  \\\n",
       "count       1151.000000       1151.000000       1151.000000   \n",
       "mean           0.000375          0.000361          0.000350   \n",
       "std            0.012815          0.012803          0.012812   \n",
       "min           -0.064195         -0.064195         -0.064195   \n",
       "25%           -0.005552         -0.005552         -0.005620   \n",
       "50%            0.000698          0.000698          0.000698   \n",
       "75%            0.006717          0.006701          0.006701   \n",
       "max            0.052104          0.052104          0.052104   \n",
       "\n",
       "       aord_log_return_0  aord_log_return_1  aord_log_return_2  \n",
       "count        1151.000000        1151.000000        1151.000000  \n",
       "mean            0.000092           0.000084           0.000086  \n",
       "std             0.009023           0.009024           0.009021  \n",
       "min            -0.042998          -0.042998          -0.042998  \n",
       "25%            -0.004583          -0.004596          -0.004596  \n",
       "50%             0.000436           0.000431           0.000431  \n",
       "75%             0.005203           0.005203           0.005203  \n",
       "max             0.034368           0.034368           0.034368  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = training_test_data[training_test_data.columns[1:]]\n",
    "classes = training_test_data[training_test_data.columns[:1]]\n",
    "\n",
    "# 80% of the training data\n",
    "training_set_size = int(len(training_test_data) * 0.8)\n",
    "test_set_size = len(training_test_data) - training_set_size\n",
    "\n",
    "training_predictors = predictors[:training_set_size]\n",
    "training_classes = classes[:training_set_size]\n",
    "test_predictors = predictors[training_set_size:]\n",
    "test_classes = classes[training_set_size:]\n",
    "\n",
    "plt.figure(figsize=(45,15))\n",
    "training_predictors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[  1 145]\n",
      " [  0 142]]\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "pipe=PMMLPipeline(steps=[('classifier',logistic)])\n",
    "\n",
    "model=pipe.fit(training_predictors.as_matrix(),training_classes.as_matrix()[:,0])\n",
    "predicted=pipe.predict(test_predictors.as_matrix())\n",
    "# Generating confusion matrix\n",
    "print (\"Confusion Matrix : \\n\",\n",
    "       metrics.confusion_matrix(test_classes.as_matrix()[:,0], predicted))\n",
    "sklearn2pmml(pipe,\"LogisticRegression.pmml\",with_repr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 93  53]\n",
      " [ 39 103]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "pipe=PMMLPipeline(steps=[('classifier',clf)])\n",
    "model=pipe.fit(training_predictors.as_matrix(),training_classes.as_matrix()[:,0])\n",
    "predicted=pipe.predict(test_predictors.as_matrix())\n",
    "sklearn2pmml(pipe,\"RandomForestClassfier.pmml\",with_repr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 86  60]\n",
      " [ 34 108]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "pipe=PMMLPipeline(steps=[('classifier',clf)])\n",
    "\n",
    "model=pipe.fit(training_predictors.as_matrix(),training_classes.as_matrix()[:,0])\n",
    "predicted=pipe.predict(test_predictors.as_matrix())\n",
    "# Generating confusion matrix\n",
    "print (\"Confusion Matrix : \\n\",\n",
    "       metrics.confusion_matrix(test_classes.as_matrix()[:,0], predicted))\n",
    "sklearn2pmml(pipe,\"RandomForestClassfier.pmml\",with_repr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[ 92  54]\n",
      " [ 30 112]]\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(2, ), random_state=1,activation='logistic',max_iter=200)\n",
    "\n",
    "pipe=PMMLPipeline(steps=[('classifier',clf)])\n",
    "\n",
    "model=pipe.fit(training_predictors.as_matrix(),training_classes.as_matrix()[:,0])\n",
    "predicted=pipe.predict(test_predictors.as_matrix())\n",
    "# Generating confusion matrix\n",
    "print (\"Confusion Matrix : \\n\",\n",
    "       metrics.confusion_matrix(test_classes.as_matrix()[:,0], predicted))\n",
    "sklearn2pmml(pipe,\"NeuralNetworkClassifier.pmml\",with_repr=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
